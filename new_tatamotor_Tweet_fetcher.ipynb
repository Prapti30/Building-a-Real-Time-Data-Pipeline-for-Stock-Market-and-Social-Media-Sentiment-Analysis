{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217bdb1d-2860-4325-9154-13830d778240",
   "metadata": {},
   "source": [
    "# code to extract tatamotor tweet from rapidapi and to convert json format data into csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46aab2a7-4ce6-463b-95ed-442f9fb52b28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./Library/Python/3.10/lib/python/site-packages (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d48601-899f-46d7-ab70-678730209f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler started. Fetching tweets every 4 hours.\n",
      "Tweet data successfully saved to CSV.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from apscheduler.schedulers.blocking import BlockingScheduler\n",
    "\n",
    "# RapidAPI tweet fetching function\n",
    "def fetch_real_time_tweets():\n",
    "    ## Define your API URL\n",
    "    url = \"\"\n",
    "    \n",
    "    # Replace these with the actual values from your RapidAPI account\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"304de52c13msh8fe6603818f4064p18d63bjsn8d62023414ae\",\n",
    "        \"x-rapidapi-host\": \"twitter-search-only.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    # Define query parameters (if needed)\n",
    "    querystring = {\"query\": \"tatamotors\", \"search_type\": \"Latest\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Returns the tweet data in JSON format\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch tweets (status code: {response.status_code})\")\n",
    "        return None\n",
    "\n",
    "# Function to filter tweets from the last 5 days and present day\n",
    "def filter_recent_tweets(tweets):\n",
    "    # Get the current date (timezone-aware) and calculate the date 5 days ago\n",
    "    end_date = datetime.now(timezone.utc)  # Make the current time timezone-aware\n",
    "    start_date = end_date - timedelta(days=5)\n",
    "    \n",
    "    # Convert 'created_at' field to datetime and filter the tweets\n",
    "    filtered_tweets = [\n",
    "        tweet for tweet in tweets \n",
    "        if 'created_at' in tweet and start_date <= datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S %z %Y') <= end_date\n",
    "    ]\n",
    "    \n",
    "    return filtered_tweets\n",
    "\n",
    "# Function to process the incoming JSON data and store in CSV\n",
    "def process_tweet_data(json_data):\n",
    "    # Extract the 'timeline' key which contains the tweets\n",
    "    tweets = json_data.get(\"timeline\", [])\n",
    "    \n",
    "    if not tweets:\n",
    "        print(\"No tweets found in the data.\")\n",
    "        return\n",
    "    \n",
    "    # Filter the tweets for the last 5 days and present day\n",
    "    recent_tweets = filter_recent_tweets(tweets)\n",
    "    \n",
    "    # Convert the filtered tweets list to a pandas DataFrame\n",
    "    df = pd.json_normalize(recent_tweets)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No recent tweets to save.\")\n",
    "        return\n",
    "    \n",
    "    # Check if the CSV file already exists\n",
    "    file_exists = os.path.isfile('tweets_tatamotor.csv')\n",
    "    \n",
    "    # If file exists, append the new data; otherwise, create a new file\n",
    "    if file_exists:\n",
    "        df.to_csv('tweets_tatamotor.csv', mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv('tweets_tatamotor.csv', mode='w', header=True, index=False)\n",
    "    \n",
    "    print(\"Tweet data successfully saved to CSV.\")\n",
    "\n",
    "# Function to fetch and process real-time tweets\n",
    "def fetch_and_process_tweets():\n",
    "    # Fetch real-time tweets from RapidAPI\n",
    "    real_time_data = fetch_real_time_tweets()\n",
    "\n",
    "    if real_time_data:\n",
    "        # Process and store the tweet data into CSV\n",
    "        process_tweet_data(real_time_data)\n",
    "\n",
    "# Scheduler setup\n",
    "if __name__ == \"__main__\":\n",
    "    scheduler = BlockingScheduler()\n",
    "    \n",
    "    # Schedule the tweet fetching function to run every 4 hours\n",
    "    scheduler.add_job(fetch_and_process_tweets, 'interval', hours=4)\n",
    "    \n",
    "    # Start the scheduler\n",
    "    print(\"Scheduler started. Fetching tweets every 4 hours.\")\n",
    "    fetch_and_process_tweets()  # Fetch tweets immediately on start\n",
    "    scheduler.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1a2cc4-565a-4717-b2d7-5dc65fefc28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea30523-3bf7-4885-a0ce-212893450a03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9906b-349d-4a58-95e7-0b0aff912d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659ff57-8498-4032-a327-42dd34da6758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c404f8-2aac-44e5-a4c4-ea18f69127a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ae3b35-95c5-4e49-927c-9913939438a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693fc31f-25b2-4772-a61f-8ff3f2287040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbc6ae-dd4e-4958-99e9-04e43359875d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c463ab-5828-4032-b159-5dfe163ac770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca4b504-cf75-440d-ad0c-7cb47fe6f405",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "2bc96689-8829-41c2-a0bf-2c71a12994c3",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "from datetime import datetime, timedelta, timezone\n",
    "\n",
    "# RapidAPI tweet fetching function\n",
    "def fetch_real_time_tweets():\n",
    "    ## Define your API URL\n",
    "    url = \"https://twitter-search-only.p.rapidapi.com/search.php\"\n",
    "    \n",
    "    # Replace these with the actual values from your RapidAPI account\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"304de52c13msh8fe6603818f4064p18d63bjsn8d62023414ae\",\n",
    "        \"x-rapidapi-host\": \"twitter-search-only.p.rapidapi.com\"\n",
    "    }\n",
    "    \n",
    "    # Define query parameters (if needed)\n",
    "    querystring = {\"query\": \"tatamotors\", \"search_type\": \"Latest\"}\n",
    "\n",
    "    response = requests.get(url, headers=headers, params=querystring)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return response.json()  # Returns the tweet data in JSON format\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch tweets (status code: {response.status_code})\")\n",
    "        return None\n",
    "\n",
    "# Function to filter tweets from the last 5 days and present day\n",
    "def filter_recent_tweets(tweets):\n",
    "    # Get the current date (timezone-aware) and calculate the date 5 days ago\n",
    "    end_date = datetime.now(timezone.utc)  # Make the current time timezone-aware\n",
    "    start_date = end_date - timedelta(days=5)\n",
    "    \n",
    "    # Convert 'created_at' field to datetime and filter the tweets\n",
    "    filtered_tweets = [\n",
    "        tweet for tweet in tweets \n",
    "        if 'created_at' in tweet and start_date <= datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S %z %Y') <= end_date\n",
    "    ]\n",
    "    \n",
    "    return filtered_tweets\n",
    "\n",
    "# Function to process the incoming JSON data and store in CSV\n",
    "def process_tweet_data(json_data):\n",
    "    # Extract the 'timeline' key which contains the tweets\n",
    "    tweets = json_data.get(\"timeline\", [])\n",
    "    \n",
    "    if not tweets:\n",
    "        print(\"No tweets found in the data.\")\n",
    "        return\n",
    "    \n",
    "    # Filter the tweets for the last 5 days and present day\n",
    "    recent_tweets = filter_recent_tweets(tweets)\n",
    "    \n",
    "    # Convert the filtered tweets list to a pandas DataFrame\n",
    "    df = pd.json_normalize(recent_tweets)\n",
    "    \n",
    "    if df.empty:\n",
    "        print(\"No recent tweets to save.\")\n",
    "        return\n",
    "    \n",
    "    # Check if the CSV file already exists\n",
    "    file_exists = os.path.isfile('tweets_tatamotor.csv')\n",
    "    \n",
    "    # If file exists, append the new data; otherwise, create a new file\n",
    "    if file_exists:\n",
    "        df.to_csv('tweets_tatamotor.csv', mode='a', header=False, index=False)\n",
    "    else:\n",
    "        df.to_csv('tweets_tatamotor.csv', mode='w', header=True, index=False)\n",
    "    \n",
    "    print(\"Tweet data successfully saved to CSV.\")\n",
    "\n",
    "# Main function to fetch and process real-time tweets\n",
    "def main():\n",
    "    # Fetch real-time tweets from RapidAPI\n",
    "    real_time_data = fetch_real_time_tweets()\n",
    "\n",
    "    if real_time_data:\n",
    "        # Process and store the tweet data into CSV\n",
    "        process_tweet_data(real_time_data)\n",
    "\n",
    "# Example of running the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb48cb58-1695-42d4-88f5-22eb651ec72e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
